{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Wrangling Template"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table Of Contents \n",
    "<ul>\n",
    "<li><a href=\"#intro\">Introduction</a></li>\n",
    "<li><a href=\"#gather\">Gather</a></li>\n",
    "<li><a href=\"#assess\">Assess</a></li>\n",
    "<li><a href=\"#clean\">Clean</a></li>\n",
    "<li><a href=\"#vizualize\">Storing, Analyzing, and Visualizing Data</a></li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='intro'></a>\n",
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Real-world data rarely comes clean. In this project, I will be using Python and its libraries, to gather data from a variety of sources and in a variety of formats, assess its quality and tidiness, then clean it. This is called data wrangling.\n",
    "\n",
    "The dataset that I will be wrangling (and analyzing and visualizing) is the tweet archive of Twitter user **@dog_rates**, also known as WeRateDogs. WeRateDogs is a Twitter account that rates people's dogs with a humorous comment about the dog. These ratings almost always have a denominator of 10. The numerators, though? Almost always greater than 10. 11/10, 12/10, 13/10, etc. Why? Because \"they're good dogs Brent.\" WeRateDogs has over 4 million followers and has received international media coverage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import packages \n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import os\n",
    "import requests \n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='gather'></a>\n",
    "## Gather"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.The WeRateDogs Twitter archive  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#read WeRateDogs twitter data from a csv file  \n",
    "twitter_archive_data = pd.read_csv('twitter-archive-enhanced.csv')\n",
    "twitter_archive_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Image Predictions File "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#download Image predictions file programmatically using request library \n",
    "url = 'https://d17h27t6h515a5.cloudfront.net/topher/2017/August/599fd2ad_image-predictions/image-predictions.tsv'\n",
    "response = requests.get(url)\n",
    "response.status_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read Image Predictions file \n",
    "image_pred = pd.read_csv(url, delimiter='\\t')\n",
    "image_pred.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Twitter API data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Unfortunately, I do not have access to Twitter API, so I will be using tweet json.text file instead, This the code used to access Twitter API\n",
    "\n",
    "#import tweepy\n",
    "#from tweepy import OAuthHandler\n",
    "#import json\n",
    "#from timeit import default_timer as timer \n",
    "#Query Twitter API for each tweet in the Twitter archive and save JSON in a text file\n",
    "#These are hidden to comply with Twitter's API terms and conditions\n",
    "#consumer_key = 'HIDDEN'\n",
    "#consumer_secret = 'HIDDEN'\n",
    "#access_token = 'HIDDEN'\n",
    "#access_secret = 'HIDDEN'\n",
    "#auth = OAuthHandler(consumer_key, consumer_secret)\n",
    "#auth.set_access_token(access_token, access_secret)\n",
    "#api = tweepy.API(auth, wait_on_rate_limit=True)\n",
    "#tweet_ids = df_1.tweet_id.values\n",
    "#len(tweet_ids)\n",
    "#Query Twitter's API for JSON data for each tweet ID in the Twitter archive\n",
    "#count = 0\n",
    "#fails_dict = {}\n",
    "#start = timer()\n",
    "#Save each tweet's returned JSON as a new line in a .txt file\n",
    "#with open('tweet_json.txt', 'w') as outfile:\n",
    " #This loop will likely take 20-30 minutes to run because of Twitter's rate limit\n",
    "    #for tweet_id in tweet_ids:\n",
    "        #count += 1\n",
    "        #print(str(count) + \": \" + str(tweet_id))\n",
    "       # try:\n",
    "        #    tweet = api.get_status(tweet_id, tweet_mode='extended')\n",
    "        #    print(\"Success\")\n",
    "       #     json.dump(tweet._json, outfile)\n",
    "       #     outfile.write('\\n')\n",
    "       # except tweepy.TweepError as e:\n",
    "      #      print(\"Fail\")\n",
    "      #      fails_dict[tweet_id] = e\n",
    "      #      pass\n",
    "#end = timer()\n",
    "#print(end - start)\n",
    "#print(fails_dict)``\n",
    "tweet = pd.read_json(r'tweet-json.txt', lines=True)\n",
    "tweet_json= pd.DataFrame(tweet, columns = ['id', 'favorite_count','retweet_count'])\n",
    "tweet_json.sample()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='assess'></a>\n",
    "## Assess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visual Assessment "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "twitter_archive_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "image_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tweet_json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Programmatic Assessment "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. The WeRateDogs Twitter archive "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_archive_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "twitter_archive_data.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "twitter_archive_data.name.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "(twitter_archive_data.duplicated()).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Image Predictions File "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "image_pred.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "image_pred.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Twitter API data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tweet_json.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(tweet_json.duplicated()).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_json.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quality \n",
    "---\n",
    "**Quality:** issues with content. Low quality data is also known as dirty data.\n",
    "\n",
    "--- \n",
    "\n",
    "#### The WeRateDogs `twitter_archive_data`  table \n",
    "\n",
    "- timestamp is captured as a string object not datetime\n",
    "- incorrect dog names that starts with lower case letters\n",
    "- None values in dogs name \n",
    "- tweet_id is captured as an int not object string  \n",
    "- archive data contains retweets along with original tweets \n",
    "- retweeted_status_id\tretweeted_status_user_id , retweeted_status_timestamp, columns are not needed for the anlaysis \n",
    "\n",
    "#### Image Predictions File  `image_pred`  table \n",
    "- inconsistent capitalization in p1,p2,p3 column, some are written in title case and lowercase\n",
    "- missing data,  Image Predictions File table has 2075 tweets information \n",
    "#### Twitter API  `tweet_json` table \n",
    "-  missing data, Twitter API table has 2354 tweets information \n",
    "\n",
    "\n",
    "\n",
    "### Tidiness\n",
    "---\n",
    "**Tidiness:** issues with structure that prevent easy analysis. Untidy data is also known as messy data. Tidy data requirements:\n",
    "- Each variable forms a column.\n",
    "- Each observation forms a row.\n",
    "- Each type of observational unit forms a table.\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "- `twitter_archive_data` , `image_pred` , `tweet_json` tables describe one tweet\n",
    "\n",
    "#### The WeRateDogs `twitter_archive_data`  table \n",
    "\n",
    "- four variables (doggo, floofer, pupper, puppo) in one column dog_stage\n",
    "\n",
    "#### Image Predictions File  `image_pred`  table  \n",
    "- p1, p2, p3 columns names are not clear \n",
    "\n",
    "#### Twitter API  `tweet_json` table  \n",
    "- id columns name needs to be tweet_id to match with `twitter_archive_data` and `image_pred` table "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='clean'></a>\n",
    "## Clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make copies of data \n",
    "twitter_archive_clean = twitter_archive_data.copy() \n",
    "image_pred_clean = image_pred.copy() \n",
    "tweet_json_clean = tweet_json.copy()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_archive_clean['rating'] = twitter_archive_clean['rating_numerator'] / twitter_archive_clean['rating_denominator'] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`twitter_archive_clean` **timestamp is captured as a string object not datetime** \n",
    "#### Define\n",
    "convert timestamp column into datetime using `to_datetime` method in pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_archive_clean.timestamp = pd.to_datetime(twitter_archive_clean.timestamp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "twitter_archive_clean.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`twitter_archive_clean`  **incorrect dog names that starts with lower case letters such as** [ by,quite,a,not, an ..etc ]\n",
    "#### Define\n",
    "`twitter_archive_clean` drop column with lower case names using `istitle()` method in pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_archive_clean = twitter_archive_clean[twitter_archive_clean['name'].str.istitle()!= False]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "twitter_archive_clean.name.str.istitle().value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`twitter_archive_clean`  **None values in dogs name**\n",
    "#### Define\n",
    "Drop rows that have the value \"None\" as a dog name, using `twitter_archive_clean['name']!= 'None'`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Code "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_archive_clean = twitter_archive_clean[twitter_archive_clean['name']!= 'None']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "(twitter_archive_clean.name == 'None').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_archive_clean.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`twitter_archive_clean`  **tweet_id is captured as an int not object string**  \n",
    "#### Define \n",
    "Convert tweet_id into a string object because tweet_id column will not be used for manipulation or calculation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_archive_clean['tweet_id'] = twitter_archive_clean['tweet_id'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_archive_clean.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`twitter_archive_clean` **archive data contains retweets along with original tweets**\n",
    "#### Define\n",
    "Removing retweets from twitter_archive_clean table using `.match()` to match `RT @dog_rates` pattren in text column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_archive_clean.text.str.match('RT @').value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_archive_clean = twitter_archive_clean[twitter_archive_clean.text.str.match('RT @')!= True]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(twitter_archive_clean.text.str.match('RT @')).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`twitter_archive_clean` **retweeted_status_id retweeted_status_user_id , retweeted_status_timestamp, columns are not needed for the anlaysis**\n",
    "#### Define\n",
    "Drop retweeted_status_id retweeted_status_user_id , retweeted_status_timestamp using `.drop()` method in pandas "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#columns before .drop()\n",
    "twitter_archive_clean.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_archive_clean.drop(['retweeted_status_id','retweeted_status_user_id','retweeted_status_timestamp'],axis=1,inplace=True) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#after .drop() \n",
    "twitter_archive_clean.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_archive_clean.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`twitter_archive_clean`  **four variables (doggo, floofer, pupper, puppo) in one column dog_stage**\n",
    "#### Define\n",
    "Create dog_stage column and fill in its values from the pupper, puppo ,floofer and doggo columns \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fill in none values with nan \n",
    "twitter_archive_clean = twitter_archive_clean.replace('None', np.nan) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create dog_stage column and assign doggo, floofer, pupper and puppo values\n",
    "twitter_archive_clean['dog_stage'] = twitter_archive_clean[['doggo','floofer','pupper','puppo']].fillna('').sum(1).replace('', np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "twitter_archive_clean.dog_stage.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " twitter_archive_clean['dog_stage'] = twitter_archive_clean['dog_stage'].replace('doggopupper', 'doggo,pupper')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " twitter_archive_clean.drop(['doggo','floofer','pupper','puppo'], axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "twitter_archive_clean.dog_stage.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_archive_clean.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_archive_clean.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`image_pred_clean` **inconsistent capitalization in p1,p2,p3 column, some are written in title case and lowercase**\n",
    "#### Define\n",
    "`image_pred_clean` convert values in p1 , p2 , p3 column into Title Case letter using `title()` method "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_pred_clean.p1 = image_pred_clean.p1.str.title()\n",
    "image_pred_clean.p2 = image_pred_clean.p2.str.title()\n",
    "image_pred_clean.p3 = image_pred_clean.p3.str.title()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "image_pred_clean.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`image_pred` **p1, p2, p3 columns names are not clear**\n",
    "\n",
    "#### Define \n",
    "\n",
    "Rename p1, p2, p3 columns to  prediction_1 ,  prediction_2 ,  prediction_3 using `rename()` \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_pred_clean.rename(columns={'p1':'pred_1','p2':'pred_2','p3':'pred_3'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "image_pred_clean.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`tweet_json` **id columns name needs to be tweet_id to match with twitter_archive_data and image_pred table**\n",
    "#### Define \n",
    "Rename id columns to tweet_id using `rename()`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_json_clean.rename(columns={'id':'tweet_id'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_json_clean.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`image_pred` **missing data, Image Predictions File table has 2075 tweets information** \n",
    "#### Define \n",
    "\n",
    "Create a new data frame and merge `image_pred` with `twitter_archive_clean`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_archive_master = pd.merge(twitter_archive_clean,image_pred_clean,\n",
    "                            on=['tweet_id'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "twitter_archive_master.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_archive_master.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_archive_master.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_json_clean.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`tweet_json_clean` missing data, Twitter API table has 2354 tweets information \n",
    "\n",
    "### Define\n",
    "merge tweet_json_clean with twitter_archive_master"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_archive_master = pd.merge(twitter_archive_master,tweet_json_clean, on=['tweet_id'], how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_archive_master"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_archive_master.to_csv(r'twitter_archive_master.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='store'></a>\n",
    "## Storing, Analyzing, and Visualizing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_data = pd.read_csv('twitter_archive_master.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating our models performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> How many times our models **first prediction** is correct?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "twitter_data.p1_dog.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">How many times our models **second prediction** is correct?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "twitter_data.p2_dog.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> How many times our models **third prediction** is correct?  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "twitter_data.p3_dog.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### Most common words used in @dog_rates twitter account tweets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Create the wordcloud object\n",
    "text = twitter_data['text'].values \n",
    "wordcloud = WordCloud(width=480, height=480, margin=0).generate(str(text))\n",
    "\n",
    "# Display the generated image:\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.margins(x=0, y=0)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dog_breeds = (twitter_data[twitter_data['p1_dog']==True]).pred_1\n",
    "\n",
    "result = dog_breeds.value_counts()[:10]\n",
    "\n",
    "result.plot(kind='barh',figsize=(10,8),color=(0.2, 0.4, 0.6, 0.6))\n",
    "plt.xlabel(\"Number of of Dogs\")\n",
    "plt.ylabel(\"Dog Breeds\")\n",
    "plt.title(\"Most Common Dog breed in @dog_rates Tweets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = 'Frogs', 'Hogs', 'Dogs', 'Logs'\n",
    "sizes = [15, 30, 45, 10]\n",
    "explode = (0, 0.1, 0, 0)  # only \"explode\" the 2nd slice (i.e. 'Hogs')\n",
    "\n",
    "fig1, ax1 = plt.subplots()\n",
    "ax1.pie(sizes, explode=explode, labels=labels, autopct='%1.1f%%',\n",
    "        shadow=True, startangle=90)\n",
    "ax1.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.\n",
    "\n",
    "plt.show() \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Dog Stage @dog_rates tweets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pie_data = twitter_data.dog_stage.value_counts()[:5]\n",
    "pie_data.plot.pie(autopct='%1.1f%%', startangle=140,figsize=(8,8),title=\"Dog Stage @dog_rates tweets\", label=\"Dog Stage\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(twitter_data.favorite_count,twitter_data.retweet_count)\n",
    "plt.title(\"Favorites vs. Retweets @dog_stage\")\n",
    "plt.xlabel(\"Favorites\")\n",
    "plt.ylabel(\"Retweets\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resources \n",
    "\n",
    "\n",
    "- https://python-graph-gallery.com/wordcloud/  \n",
    "- https://stackoverflow.com/questions/43606339/generate-word-cloud-from-single-column-pandas-dataframe \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
